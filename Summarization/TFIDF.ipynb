{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Text Summarization using TFIDF\n",
    "============================\n",
    "    \n",
    "### From Leaf by Niggle - JRR Tolkien\n",
    "    \n",
    "#### Automatic text summarization is the task of producing a **concise and fluent summary** without any human help while preserving the meaning of the original text document.\n",
    "\n",
    "####  There are two different approach for Summarization: Extractive and Abstractive\n",
    "\n",
    "#### **Extractive:** selects important parts  of the text to produce a reduced version\n",
    "\n",
    "####  **Abstractive:** aim at producing summary by interpreting the text using advanced natural language techniques in order to generate a new shorter text\n",
    "\n",
    "####  This notebook to performs **Extractive Summarization** using **TFIDF** in **Leaf by Niggle** text.\n",
    "    \n",
    "#### Two forms of summarization are used: manual calculation of the steps and the use of the Scikit-Learn vectorization library  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> TFIDF stands for: Term Frequency - Inverse Document Frequency\n",
    "    \n",
    "    This is a technique to quantify a word in documents, computing a weight to each word which signifies the importance of the word in the document and corpus.\n",
    "    \n",
    "    \n",
    "   **Document**: It can be a phrase, a text file a pandas row etc...\n",
    "    \n",
    "   **TF (Term Frequency)**: Frequency of a word in a document (term T in document D)\n",
    "    \n",
    "    *TF(T,D) = count of T in D/ number of words in D*\n",
    "   \n",
    "   **DF (Document Frequency)**: This measures the importance of document in whole set of corpus (term T in the document set N)\n",
    "   \n",
    "    *DF(T) = occurrence of T in documents*\n",
    "   \n",
    "   **IDF (Inverse Document Frequency)**: IDF is the inverse of the document frequency which measures the informativeness of term T.\n",
    "    \n",
    "    *IDF(T) = log(N/(DF+1))*\n",
    "    \n",
    "   **The whole expression is:**\n",
    "    \n",
    "    \n",
    "    TF-IDF(T, D) = TF(T, D) * log(N/(DF + 1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "# Libraries\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Python \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from src import DataProcessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "\n",
    "# NLP\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# ML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../datasets/leaf_by_niggle.txt'\n",
    "file = open(folder, 'r')\n",
    "poem = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of Documents =  591\n",
      "\n",
      " First Sentence =  There was once a little man called Niggle, who had a long journey to make.\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = sent_tokenize(poem)\n",
    "documents_total = len(tokenized_sentences)\n",
    "first_sentence = tokenized_sentences[0]\n",
    "print('\\n Number of Documents = ', documents_total)\n",
    "print('\\n First Sentence = ', first_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Manual Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Matrix of the words in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original sentence =  There was once a little man called Niggle, who had a long journey to make.\n",
      "\n",
      " Words frequency in sentence =  {'There': 1, 'was': 1, 'once': 1, 'a': 2, 'little': 1, 'man': 1, 'called': 1, 'Niggle,': 1, 'who': 1, 'had': 1, 'long': 1, 'journey': 1, 'to': 1, 'make.': 1}\n"
     ]
    }
   ],
   "source": [
    "def generate_words_frequency_matrix(tokenized_sentences):\n",
    "    \n",
    "    frequency_matrix = {}\n",
    "\n",
    "    for sentence in tokenized_sentences:\n",
    "        words_matrix = {}\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word not in words_matrix:\n",
    "                words_matrix[word] = 1\n",
    "            else:\n",
    "                words_matrix[word] +=1\n",
    "        frequency_matrix[sentence] = words_matrix\n",
    "                \n",
    "    return frequency_matrix\n",
    "\n",
    "words_frequency_matrix =  generate_words_frequency_matrix(tokenized_sentences)\n",
    "\n",
    "print(\"\\n Original sentence = \", first_sentence)\n",
    "print(\"\\n Words frequency in sentence = \", words_frequency_matrix[first_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Term Frequency Matrix\n",
    "\n",
    "    TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original sentence =  There was once a little man called Niggle, who had a long journey to make.\n",
      "\n",
      " Words frequency in sentence =  {'There': 1, 'was': 1, 'once': 1, 'a': 2, 'little': 1, 'man': 1, 'called': 1, 'Niggle,': 1, 'who': 1, 'had': 1, 'long': 1, 'journey': 1, 'to': 1, 'make.': 1}\n",
      "\n",
      " TF for words in each sentence =  {'There': 0.07142857142857142, 'was': 0.07142857142857142, 'once': 0.07142857142857142, 'a': 0.14285714285714285, 'little': 0.07142857142857142, 'man': 0.07142857142857142, 'called': 0.07142857142857142, 'Niggle,': 0.07142857142857142, 'who': 0.07142857142857142, 'had': 0.07142857142857142, 'long': 0.07142857142857142, 'journey': 0.07142857142857142, 'to': 0.07142857142857142, 'make.': 0.07142857142857142}\n"
     ]
    }
   ],
   "source": [
    "def generate_term_frequency_matrix(words_frequency_matrix):\n",
    "    \n",
    "    terms_frequency_matrix = {}\n",
    "\n",
    "    for document, terms_frequency_dict in words_frequency_matrix.items():   \n",
    "\n",
    "        tf_matrix = {}        \n",
    "        number_of_terms_in_document = len(terms_frequency_dict)    \n",
    "\n",
    "        for term_t, number_term_t_in_document in terms_frequency_dict.items():        \n",
    "            tf_matrix[term_t] = number_term_t_in_document/number_of_terms_in_document\n",
    "        terms_frequency_matrix[document] = tf_matrix\n",
    "        \n",
    "    return terms_frequency_matrix\n",
    "\n",
    "terms_frequency_matrix = generate_term_frequency_matrix(words_frequency_matrix)\n",
    "\n",
    "print(\"\\n Original sentence = \", first_sentence)\n",
    "print(\"\\n Words frequency in sentence = \", words_frequency_matrix[first_sentence])\n",
    "print(\"\\n TF for words in each sentence = \", terms_frequency_matrix[first_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "\n",
    "    IDF(t) = log_e(Total number of documents / Number of documents with term t in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " IDF for word There =  1.4419568376564116\n"
     ]
    }
   ],
   "source": [
    "def generate_inverse_document_frequency(words_frequency_matrix):\n",
    "\n",
    "\n",
    "    N = len(words_frequency_matrix)\n",
    "    idf = {}\n",
    "\n",
    "    for doc, word_dict in words_frequency_matrix.items():       \n",
    "        for word, count in word_dict.items():        \n",
    "            val = 0        \n",
    "            for sent in tokenized_sentences:                \n",
    "                if word in sent:                \n",
    "                    val+=1       \n",
    "            idf[word] = math.log10(N / (val + 1))     \n",
    "                \n",
    "    return idf\n",
    "\n",
    "inverse_document_frequency = generate_inverse_document_frequency(words_frequency_matrix)\n",
    "\n",
    "print(\"\\n IDF for word There = \", inverse_document_frequency['There'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfidf(terms_frequency_matrix, inverse_document_frequency):\n",
    "    \n",
    "    tfidf = {}\n",
    "    for words, tf_dict in terms_frequency_matrix.items():\n",
    "        for word, score in tf_dict.items():\n",
    "            tfidf[word] = score * inverse_document_frequency[word]\n",
    "            \n",
    "    return tfidf\n",
    "\n",
    "tfidf = generate_tfidf(terms_frequency_matrix, inverse_document_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TFIDF for word There =  0.09613045584376077\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n TFIDF for word There = \", tfidf['There'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Sentences and Find a Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_sentences(tokenized_sentences, tfidf):\n",
    "\n",
    "    scored_sentence = {}\n",
    "\n",
    "    for sent in tokenized_sentences:\n",
    "        score = 0\n",
    "        for word in word_tokenize(sent):\n",
    "                if word in tfidf:\n",
    "                    score += 1            \n",
    "\n",
    "        scored_sentence[sent] = score\n",
    "        \n",
    "    return scored_sentence\n",
    "\n",
    "scored_sentence = generate_score_sentences(tokenized_sentences, tfidf)\n",
    "\n",
    "def generate_threshold(scored_sentence, total):\n",
    "    sum_score = 0\n",
    "\n",
    "    for sent, scores in scored_sentence.items():\n",
    "        sum_score += scores\n",
    "    \n",
    "    return np.round(sum_score/(total-(total*0.15)))    \n",
    "\n",
    "threshold =  generate_threshold(scored_sentence, documents_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original sentence =  There was once a little man called Niggle, who had a long journey to make.\n",
      "\n",
      " Scored sentence =  16\n",
      "\n",
      " Threshold =  15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Original sentence = \", first_sentence)\n",
    "print('\\n Scored sentence = ', scored_sentence[first_sentence])\n",
    "print('\\n Threshold = ', threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_text(scored_sentence, threshold):\n",
    "    summary = ' '\n",
    "    for sent, score in scored_sentence.items():\n",
    "        if score >= threshold:\n",
    "            summary += sent + ' '\n",
    "            \n",
    "    return summary\n",
    "\n",
    "summary = generate_summary_text(scored_sentence, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Summarization Using TFIDF from Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectors = vectorizer.fit_transform(tokenized_sentences)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "dense_list = dense.tolist()\n",
    "\n",
    "df = pd.DataFrame(dense_list, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>ache</th>\n",
       "      <th>acquaintances</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>adjoining</th>\n",
       "      <th>advice</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1329 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  about  absolutely  absorbed  ache  acquaintances  actually  added  \\\n",
       "302   0.0    0.0         0.0       0.0   0.0            0.0       0.0    0.0   \n",
       "113   0.0    0.0         0.0       0.0   0.0            0.0       0.0    0.0   \n",
       "545   0.0    0.0         0.0       0.0   0.0            0.0       0.0    0.0   \n",
       "45    0.0    0.0         0.0       0.0   0.0            0.0       0.0    0.0   \n",
       "359   0.0    0.0         0.0       0.0   0.0            0.0       0.0    0.0   \n",
       "\n",
       "     adjoining  advice  ...  written     wrong  year  years  yellow  yes  yet  \\\n",
       "302        0.0     0.0  ...      0.0  0.000000   0.0    0.0     0.0  0.0  0.0   \n",
       "113        0.0     0.0  ...      0.0  0.000000   0.0    0.0     0.0  0.0  0.0   \n",
       "545        0.0     0.0  ...      0.0  0.000000   0.0    0.0     0.0  0.0  0.0   \n",
       "45         0.0     0.0  ...      0.0  0.223418   0.0    0.0     0.0  0.0  0.0   \n",
       "359        0.0     0.0  ...      0.0  0.000000   0.0    0.0     0.0  0.0  0.0   \n",
       "\n",
       "     you  young  your  \n",
       "302  0.0    0.0   0.0  \n",
       "113  0.0    0.0   0.0  \n",
       "545  0.0    0.0   0.0  \n",
       "45   0.0    0.0   0.0  \n",
       "359  0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 1329 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_sentence = generate_score_sentences(tokenized_sentences, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold =  generate_threshold(scored_sentence, documents_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original sentence =  There was once a little man called Niggle, who had a long journey to make.\n",
      "\n",
      " Scored sentence =  11\n",
      "\n",
      " Threshold =  13.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Original sentence = \", first_sentence)\n",
    "print('\\n Scored sentence = ', scored_sentence[first_sentence])\n",
    "print('\\n Threshold = ', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_summary = generate_summary_text(scored_sentence, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text\n",
      "\n",
      "Text lenght =  39470\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There was once a little man called Niggle, who had a long journey to make. He did not want to go, indeed the whole idea was distasteful to him; but he could not get out of it. He knew he would have to start some time, but he did not hurry with his preparations.\\n\\nNiggle was a painter. Not a very successful one, partly because he had many other things to do. Most of these things he thought were a nuisance; but he did them fairly well, when he could not get out of them: which (in his opinion) was far too often. The laws in his country were rather strict. There were other hindrances, too. For one thing, he was sometimes just idle, and did nothing at all. For another, he was kind-hearted, in a way. You know the sort of kind heart: it made him uncomfortable more often than it made him do anything; and even when he did anything, it did not prevent him from grumbling, losing his temper, and swearing (mostly to himself). All the same, it did land him in a good many odd jobs for his neighbour, Mr. Parish, a man with a lame leg. Occasionally he even helped other people from further off, if they came and asked him to. Also, now and again, he remembered his journey, and began to pack a few things in an ineffectual way: at such times he did not paint very much.\\n\\nHe had a number of pictures on hand; most of them were too large and ambitious for his skill. He was the sort of painter who can paint leaves better than trees. He used to spend a long time on a single leaf, trying to catch its shape, and its sheen, and the glistening of dewdrops on its edges. Yet he wanted to paint a whole tree, with all of its leaves in the same style, and all of them different.\\n\\nThere was one picture in particular which bothered him. It had begun with a leaf caught in the wind, and it became a tree; and the tree grew, sending out innumerable branches, and thrusting out the most fantastic roots. Strange birds came and settled on the twigs and had to be attended to. Then all round the Tree, and behind it'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original text\\n\") \n",
    "print('Text lenght = ', len(poem))\n",
    "print('\\n')\n",
    "poem[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized text (TFIDF Manual) \n",
      "\n",
      "Text lenght =  24597\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' There was once a little man called Niggle, who had a long journey to make. He did not want to go, indeed the whole idea was distasteful to him; but he could not get out of it. He knew he would have to start some time, but he did not hurry with his preparations. Not a very successful one, partly because he had many other things to do. Most of these things he thought were a nuisance; but he did them fairly well, when he could not get out of them: which (in his opinion) was far too often. You know the sort of kind heart: it made him uncomfortable more often than it made him do anything; and even when he did anything, it did not prevent him from grumbling, losing his temper, and swearing (mostly to himself). All the same, it did land him in a good many odd jobs for his neighbour, Mr. Parish, a man with a lame leg. Occasionally he even helped other people from further off, if they came and asked him to. Also, now and again, he remembered his journey, and began to pack a few things in an ineffectual way: at such times he did not paint very much. He had a number of pictures on hand; most of them were too large and ambitious for his skill. He used to spend a long time on a single leaf, trying to catch its shape, and its sheen, and the glistening of dewdrops on its edges. Yet he wanted to paint a whole tree, with all of its leaves in the same style, and all of them different. It had begun with a leaf caught in the wind, and it became a tree; and the tree grew, sending out innumerable branches, and thrusting out the most fantastic roots. Strange birds came and settled on the twigs and had to be attended to. Then all round the Tree, and behind it, through the gaps in the leaves and boughs, a country began to open out; and there were glimpses of a forest marching over the land, and of mountains tipped with snow. Niggle lost interest in his other pictures; or else he took them and tacked them on to the edges of his great picture. Soon the canvas became so large that he had to g'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summarized text (TFIDF Manual) \\n\") \n",
    "print('Text lenght = ', len(summary))\n",
    "print('\\n')\n",
    "summary[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized text (TFIDF from Scikit Learn) \n",
      "\n",
      "Text lenght =  23439\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' He did not want to go, indeed the whole idea was distasteful to him; but he could not get out of it. He knew he would have to start some time, but he did not hurry with his preparations. Most of these things he thought were a nuisance; but he did them fairly well, when he could not get out of them: which (in his opinion) was far too often. You know the sort of kind heart: it made him uncomfortable more often than it made him do anything; and even when he did anything, it did not prevent him from grumbling, losing his temper, and swearing (mostly to himself). All the same, it did land him in a good many odd jobs for his neighbour, Mr. Parish, a man with a lame leg. Occasionally he even helped other people from further off, if they came and asked him to. Also, now and again, he remembered his journey, and began to pack a few things in an ineffectual way: at such times he did not paint very much. He had a number of pictures on hand; most of them were too large and ambitious for his skill. He used to spend a long time on a single leaf, trying to catch its shape, and its sheen, and the glistening of dewdrops on its edges. Yet he wanted to paint a whole tree, with all of its leaves in the same style, and all of them different. It had begun with a leaf caught in the wind, and it became a tree; and the tree grew, sending out innumerable branches, and thrusting out the most fantastic roots. Strange birds came and settled on the twigs and had to be attended to. Then all round the Tree, and behind it, through the gaps in the leaves and boughs, a country began to open out; and there were glimpses of a forest marching over the land, and of mountains tipped with snow. Niggle lost interest in his other pictures; or else he took them and tacked them on to the edges of his great picture. Soon the canvas became so large that he had to get a ladder; and he ran up and down it, putting in a touch here, and rubbing out a patch there. When people came to call, he seemed polite enough, th'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summarized text (TFIDF from Scikit Learn) \\n\") \n",
    "print('Text lenght = ', len(skl_summary))\n",
    "print('\\n')\n",
    "skl_summary[0:2000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
